{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import es_core_news_sm\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import BucketIterator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(sys.path[0], 'data/spa.txt')\n",
    "lines= pd.read_table(data_path,  names =['eng', 'spa', 'comments'])\n",
    "train,valid = train_test_split(lines, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv')\n",
    "valid.to_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spacy for tokenization - provides good support for tokenization in languages other than english\n",
    "eng_field = Field(tokenize=\"spacy\",\n",
    "                 tokenizer_language=\"en\",\n",
    "                 init_token=\"<sos>\",\n",
    "                 eos_token = \"<eos>\",\n",
    "                 lower = True)\n",
    "\n",
    "spa_field = Field(tokenize=\"spacy\",\n",
    "                 tokenizer_language=\"es\",\n",
    "                 init_token=\"<sos>\",\n",
    "                 eos_token = \"<eos>\",\n",
    "                 lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data_fields = [(\"id\", None), ('eng', eng_field), ('spa', spa_field),('comments',None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = TabularDataset.splits(\n",
    "\n",
    "path = './',\n",
    "train='train.csv',\n",
    "validation='valid.csv',\n",
    "format = 'csv',\n",
    "skip_header = True,\n",
    "fields = tabular_data_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'eng': ['i', 'could', 'hardly', 'endure', 'the', 'pain', '.'],\n 'spa': ['apenas', 'podía', 'soportar', 'el', 'dolor', '.']}"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "valid[122].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_field.build_vocab(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_field.build_vocab(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "13365"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len(spa_field.vocab)\n",
    "len(eng_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'eng': ['have', 'you', 'known', 'tom', 'long', '?'],\n 'spa': ['¿', 'conoces', 'a', 'tom', 'desde', 'hace', 'mucho', 'tiempo', '?']}"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = BucketIterator.splits((train, valid),\n",
    "batch_size = 32, sort_key = lambda x: len(x.eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on Batch in module torchtext.data.batch object:\n\nclass Batch(builtins.object)\n |  Batch(data=None, dataset=None, device=None)\n |  \n |  Defines a batch of examples along with its Fields.\n |  \n |  Attributes:\n |      batch_size: Number of examples in the batch.\n |      dataset: A reference to the dataset object the examples come from\n |          (which itself contains the dataset's Field objects).\n |      train: Deprecated: this attribute is left for backwards compatibility,\n |          however it is UNUSED as of the merger with pytorch 0.4.\n |      input_fields: The names of the fields that are used as input for the model\n |      target_fields: The names of the fields that are used as targets during\n |                     model training\n |  \n |  Also stores the Variable for each column in the batch as an attribute.\n |  \n |  Methods defined here:\n |  \n |  __init__(self, data=None, dataset=None, device=None)\n |      Create a Batch from a list of examples.\n |  \n |  __iter__(self)\n |  \n |  __len__(self)\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  __str__(self)\n |      Return str(self).\n |  \n |  ----------------------------------------------------------------------\n |  Class methods defined here:\n |  \n |  fromvars(dataset, batch_size, train=None, **kwargs) from builtins.type\n |      Create a Batch directly from a number of Variables.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\nNone\ntensor([[    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n             2,     2],\n        [    5,    46,   707,    30,    16,     9,    55,     5,     5,    15,\n           336,     5,     6,    19,    94,    15,    29,    35,    28,   131,\n            35,     5,    15,     9,    16,    25,     5,    50,    25,    31,\n            10,     5],\n        [  156,    28,   476,  1009,   268,    51,   124,    90,   129,   129,\n            17,   132,  2162,  2829,    17,  1393,   338,   478,   891,   260,\n          2200,    14,   471,    58,    17,   985,   685,    33,   172,     8,\n            84,    54],\n        [    7, 10366,    22,    53,    43,    13,   308,  1735,     7,    69,\n          6358,     8,  6868,    22,     9,     7,    14,    12,  1616,    18,\n            31,    13,    75,    13,    10,    12,    28,    13,  3667,   946,\n          3368,    14],\n        [   37,     6,    87,   150,     9,   840,    11,    74,     9,    38,\n            20,    76,   189,    78,    75,   761,     8,   142,  1329,    46,\n          6541,   458,     6,    44,   130,    18,    80,   254,     4,    11,\n            57,    60],\n        [   47,  3765,     4,    36,   138,   102,     3,   545,    17,    10,\n          1084,   193,   153,    73,     8,    34,    39,  2363,     4,    37,\n             4,   204,  2153,    72,    20,   252,     4,    44,     3,     3,\n            41,     8],\n        [    4,    11,     3,     6,  1066,   126,     1,   140,   125,  5515,\n            12,     4,    42,   276,    91,   784,    24,     7,     3,  4795,\n             3,    29,   444,    32,   412,    17,     3,    28,     1,     1,\n         10353,  1710],\n        [    3,     3,     1,  2083,   613,     4,     1,     4,     6,    20,\n          6396,     3,   346,    29,    48,   883,     7,    24,     1,    83,\n             1,     8,     4,  2923,     7,  2707,     1,    76,     1,     1,\n            36,     4],\n        [    1,     1,     1,     4,   581,     3,     1,     3,   159,   581,\n             4,     1,     4,     7,    11,   254,   200,     4,     1,    10,\n             1,    31,     3,    48,    37,     4,     1,    47,     1,     1,\n            34,     3],\n        [    1,     1,     1,     3,     4,     1,     1,     1,   164,    19,\n             3,     1,     3,   732,     3,   836,    11,     3,     1,   879,\n             1,   570,     1,     4,    38,     3,     1,     4,     1,     1,\n          3470,     1],\n        [    1,     1,     1,     1,     3,     1,     1,     1,    15,    34,\n             1,     1,     1,     4,     1,    15,     3,     1,     1,    88,\n             1,     4,     1,     3,     8,     1,     1,     3,     1,     1,\n            17,     1],\n        [    1,     1,     1,     1,     1,     1,     1,     1,   308,   402,\n             1,     1,     1,     3,     1,    21,     1,     1,     1,    37,\n             1,     3,     1,     1,     4,     1,     1,     1,     1,     1,\n            56,     1],\n        [    1,     1,     1,     1,     1,     1,     1,     1,     4,     4,\n             1,     1,     1,     1,     1,    10,     1,     1,     1,     4,\n             1,     1,     1,     1,     3,     1,     1,     1,     1,     1,\n             4,     1],\n        [    1,     1,     1,     1,     1,     1,     1,     1,     3,     3,\n             1,     1,     1,     1,     1,   730,     1,     1,     1,     3,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             3,     1],\n        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,   794,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1],\n        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     4,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1],\n        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     3,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1]])\n"
    }
   ],
   "source": [
    "for i, (batch) in enumerate(train_iter):\n",
    "    print(help(batch))\n",
    "    print(batch.eng)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_iter):\n",
    "    src1 = batch.eng[:,0].numpy()\n",
    "    trg1 = batch.spa[:,0].numpy()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_mapping(src, trg):\n",
    "    src = np.copy(src)\n",
    "    vfunc = np.vectorize(lambda x: eng_field.vocab.itos[x])\n",
    "    saved_src = vfunc(src)\n",
    "    \n",
    "    trg = np.copy(trg)\n",
    "    xfunc = np.vectorize(lambda x: spa_field.vocab.itos[x])\n",
    "    saved_trg = xfunc(trg)\n",
    "    \n",
    "    return saved_src, saved_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'torch.Tensor'>\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(val_iter):\n",
    "    print(type(batch.eng))\n",
    "    if (type(batch.eng) == torch.Tensor):\n",
    "        src2 = batch.eng[:,0].numpy()\n",
    "        trg2 = batch.spa[:,0].numpy()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[  2   5 113 579 187 116  25 811   4   3   1   1   1   1   1]\n[  2 756 904  14  55  44 435   5 179   4   3   1   1   1   1   1   1]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array(['<sos>', 'i', \"'d\", 'rather', 'stay', 'home', 'this', 'weekend',\n        '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n       dtype='<U7'),\n array(['<sos>', 'prefiero', 'quedarme', 'en', 'casa', 'este', 'fin', 'de',\n        'semana', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>',\n        '<pad>', '<pad>'], dtype='<U8'))"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "print(src1)\n",
    "print(trg1)\n",
    "confirm_mapping(src1, trg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[   2  136 1113    4    3]\n[    2  8419 14570     4     3     1     1     1]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array(['<sos>', 'say', 'cheese', '.', '<eos>'], dtype='<U6'),\n array(['<sos>', 'decid', 'patata', '.', '<eos>', '<pad>', '<pad>',\n        '<pad>'], dtype='<U6'))"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "print(src2)\n",
    "print(trg2)\n",
    "confirm_mapping(src2, trg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n"
    }
   ],
   "source": [
    "print(type(src2) == np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-name",
   "language": "python",
   "name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}